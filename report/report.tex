\documentclass[11pt,a4paper,twoside]{report}
  \usepackage{a4wide}
  \usepackage{epsfig}
  \usepackage{amsmath}
  \usepackage{tabu}
  \usepackage{amsfonts}
  \usepackage{latexsym}
  \usepackage[utf8]{inputenc}
  \usepackage{listings}
  \usepackage{color}
  \usepackage{titlesec}    
  \usepackage{enumitem}
  \usepackage[catalan]{babel}
  \usepackage{newunicodechar}
  \usepackage{graphicx}
  \usepackage{subcaption}
  \usepackage{float}
  \usepackage{verbatim}
  \usepackage{booktabs}
  \usepackage[table,xcdraw]{xcolor}

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

\newunicodechar{Ŀ}{\L.}
\newunicodechar{ŀ}{\l.}


% \titleformat{\chapter}
%   {\normalfont\LARGE\bfseries}{\thechapter}{1em}{}
% \titlespacing*{\chapter}{0pt}{3.5ex plus 1ex minus .2ex}{2.3ex plus .2ex}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\usepackage{hyperref}
\hypersetup{
  colorlinks=false, %set true if you want colored links
  linktoc=all,     %set to all if you want both sections and subsections linked
  linkcolor=blue,  %choose some color if you want links to stand out
}

\lstset{frame=tb,
  language=Scala,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  extendedchars=true,
  literate={á}{{\'a}}1 {à}{{\`a}}1 {ã}{{\~a}}1 {é}{{\'e}}1 {è}{{\`e}}1 {í}{{\'i}}1 {ï}{{\"i}}1 {ó}{{\'o}}1 {ò}{{\`o}}1 {ú}{{\'u}}1 {ü}{{\"u}}1 {ç}{{\c{c}}}1
        {Á}{{\'A}}1 {À}{{\`A}}1 {Ã}{{\~A}}1 {É}{{\'E}}1 {È}{{\`E}}1 {Í}{{\'I}}1 {Ï}{{\"I}}1 {Ó}{{\'O}}1 {Ò}{{\`O}}1 {Ú}{{\'U}}1 {Ü}{{\"U}}1 {Ç}{{\c{C}}}1
  }

\setlength{\footskip}{50pt}
\setlength{\parindent}{0cm} \setlength{\oddsidemargin}{-0.5cm} \setlength{\evensidemargin}{-0.5cm}
\setlength{\textwidth}{17cm} \setlength{\textheight}{23cm} \setlength{\topmargin}{-1.5cm} \addtolength{\parskip}{2ex}
\setlength{\headsep}{1.5cm}


\renewcommand{\contentsname}{Continguts}
%\renewcommand{\chaptername}{Pr\`actica}
\setcounter{chapter}{0}



\begin{document}

\title{Pràctica de programció funcional + orientada a objectes\\
\large Similitud entre documents}
\author{Ismael El Habri, Lluís Trilla}
\date{16 d'octubre de 2018}
\maketitle

\tableofcontents

\chapter{Codi de la pràctica}

Hem dividit el nostre codi en dos fitxers, SimilitudEntreDocuments.scala i MapReduceFramework.scala.

\section{Fitxer SimilitudEntreDocuments.scala}

Aquest fitxer inclou les següents funcions:
\subsection{Funcions de freqüència}

\subsubsection{Funció Freqüència}
\begin{lstlisting}
  //Rebent una String i un enter n dóna com a resultat una llista amb tuples (n-grames, freqüència)
  def freq(text:String, n:Int):List[(String, Int)] =
    normalitza(text).split(" +").sliding(n).toList
      .map(_.mkString(" ")).groupBy(identity).mapValues(_.length).toList
\end{lstlisting}

Aquesta funció rep una String amb el contingut d'un fitxer i un enter, i torna una Llista amb tuples n-grames (on n és l'enter donat), Nombre. El nombre és el nombre de vagades que apareix en el fitxer la paraula amb la que va agrupat.
En la funció usem la funció que explicarem a continuació, \texttt{normalitza}. A part, usem les següents funcions de Scala:
\begin{itemize}
  \item \texttt{split}: separa una string en una llista de strings usant un delimitador donat
  \item \texttt{sliding}: per fer grups de n-elements amb els elements de la llista de Strings.
  \item \texttt{map}: L'usem per convertir cada grup resultant de la funció anterior en Strings.
  \item \texttt{mkString}: Per crear Strings a partir de la llista.
  \item \texttt{groupBy}: S'usa per agrupar els elements d'una llista donada una certa relació, en aquest cas volem agrupar els ideals,
    això dóna un resultat del tipus \texttt{Map[String,List[String]]}.
  \item \texttt{mapValues}: L'usem per reduir els resultats dels valors anteriors en un element de Diccionari, en aquest cas: String -> Int.
\end{itemize}

\subsubsection{Funció de normalització}
\begin{lstlisting}
  //Rep una String i la normalitza (canvia tot el que no és lletra per espais i passa la string a minúscules)
  def normalitza(text:String):String =
    text.map(c=> if(c.isLetter) c else ' ').toLowerCase().trim
\end{lstlisting}

Funció que per cada element de una String fa un map per canviar tots els elements que no són lletres per espais, passa el resultat del map a minúscules.

De les funcions de Scala no n'usem cap de nova, apart de \texttt{trim} que ens treu els espais generats al principi i al final de la String normalitzada.

\subsubsection{Funció de Freqüències sense \textit{StopWords}}
\begin{lstlisting}
  //Rep una String i una llista de Strings amb stop words, i fa el vector de frequencies filtran les stop words.
  def nonStopFreq(text:String, stop:List[String], n:Int):List[(String, Int)] =
    normalitza(text).split(" +").filterNot{a => stop.contains(a)}.sliding(n).toList.map(_.mkString(" ")).groupBy(identity).mapValues(_.length).toList
\end{lstlisting}

Funció molt semblant a la de freqüències normals, però en aquest cas, abans del sliding, filtrem les \textit{stopwords} donades.

\subsubsection{Funció de distribució de paraules}
\begin{lstlisting}
  //Obtenim les 10 frequències més frequents, i les 5 menys frequents
  def paraulafreqfreq(llistaFrequencies:List[(String,Int)]): Unit = {
    val stringFrequencies:String = llistaFrequencies.map(_._2.toString.concat(" ")).mkString
    val freqfreqList = stringFrequencies
      .split(" +").groupBy(identity).mapValues(_.length).toList.sortBy(-_._2)
    println("Les 10 frequencies mes frequents:")
    for(frequencia <- freqfreqList.slice(0,10))
      println(frequencia._2 + " paraules apareixen " + frequencia._1 +" vegades")
    println("Les 5 frequencies menys frequents:")
    for(frequencia <- freqfreqList.slice(freqfreqList.length-5,freqfreqList.length).sortBy(-_._2))
      println(frequencia._2 + " paraules apareixen " + frequencia._1 +" vegades")
  }
\end{lstlisting}

Funció on busquem les 10 freqüències més freqüents, i les 5 que ho son menys. Esta implementada aprofitant la mateixa funció freq original. Primer de tot transformem l'estructura de dades que conté les freqüències en una string amb les freqüències separades per espais, i després nomes cal usar la funció freq per tal d'obtenir les freqüències de freqüències

\subsection{Funcions de Comparació}

La única funció per comparar és la funció \texttt{cosinesim}, però abans, introduirem les funcions auxiliars utilitzades per fer-lo.

\subsubsection{Funcions auxiliars}

\begin{lstlisting}
  //Rep dos vectors de frequencies absolutes i les converteix a tf.
  def freqAtf(llistaFreq:List[(String, Int)]):List[(String, Double)] = {
    val mesfrequent = llistaFreq.maxBy(_._2)._2
    llistaFreq.map{a=> (a._1, a._2.toDouble/mesfrequent)}
  }

  //Retorna la paraula no-stop més frequent del text introduït, junt amb la seva freqüència
  def mesFrequent(text:String, stop:List[String], n:Int) = nonStopFreq(text, stop, n).maxBy(_._2)

  //Busquem les paraules q no tenim a txt1 de txt2 i les afegim amb frequencia = 0 a txt1 Al final ordenem alfabeticament, per tenir el mateix ordre en els dos vectors!
  def alinearVector(aAlinear:List[(String, Double)], suport:List[(String, Double)]):List[(String, Double)] ={
    val aAlinearMap = aAlinear.toMap
    (aAlinear ::: (for (b<-suport if !aAlinearMap.contains(b._1)) yield (b _1, 0.0))) sortBy(_._1)
  }
\end{lstlisting}

\begin{enumerate}
  \item \texttt{freqAtf}: passa les freqüències absolutes a freqüència \textit{tf}.
  \item \texttt{mesFrequent}: ens dóna l'element més freqüent de la llista de freqüències.
  \item \texttt{alinearVector}: Donat un vector a alinear, i un vector amb el qual s'ha de alinear, alinea el vector a alinear.
\end{enumerate}

\subsubsection{Funció cosinesim}

\begin{lstlisting}
  //Rep dos vectors amb les paraules i les seves freqüencies tf, i retorna la semblança entre aquests dos fitxers.
  def cosinesim (txt1:List[(String,Double)], txt2:List[(String,Double)]):Double =
    (for ((a, b) <- alinearVector(txt1,txt2) zip alinearVector(txt2,txt1)) yield a._2 * b._2).foldLeft(0.0)(_ + _)/(sqrt(txt1.foldLeft(0.0){(a,b)=> a+(b._2*b._2)}) * sqrt(txt2.foldLeft(0.0){(a,b)=> a+(b._2*b._2)}) )
\end{lstlisting}

Sent la fórmula de simi\l.litud: \[sim(a,b) = \frac{a \cdot b}{sqrt{\sum_{i=1}^m a[i]^2} \cdot sqrt{\sum_{i=1}^m b[i]^2}}\]

El cosinesim ha de fer la divisió del producte escalar dels dos vectors alineats entre el resultat de la multiplicació de la arrel de la suma de cada \textit{tf} dels dos vectors de frequencies.

La funció dona per suposat que la freqüència donada és freqüència \textit{tf}.

\subsection{Funcions pel MapReduce}

\subsubsection{Funció per Llegir fitxers XML}
\begin{lstlisting}
  //Rep el nom de un docoment de la wiki, el llegeix i el filtra, resultant en el nom de l'article, el contingut d'aquest i una llista de referències cap a altres articles
  def tractaXMLdoc(docName:String): (String, String, List[String]) = {
    val xmlleg=new java.io.InputStreamReader(new java.io.FileInputStream(docName), "UTF-8")
    val xmllegg = XML.load(xmlleg)
    // obtinc el titol
    val titol=(xmllegg \\ "title").text
    // obtinc el contingut de la pàgina
    val contingut = (xmllegg \\ "text").text

    // identifico referències
    val refs=(new Regex("\\[\\[[^\\]]*\\]\\]") findAllIn contingut).toList
    // elimino les que tenen : (fitxers) i # (referencies internes)
    val kk = refs.filterNot(x=> x.contains(':') || x.contains('#')).map(_.takeWhile(_!='|'))
    (normalitza(titol), contingut, kk.map(normalitza).distinct)
  }
\end{lstlisting}

Funció basada en el programa Scala donat pel professor, modificada per tal de eliminar referencies internes
(les que contenen el caràcter '\texttt{\#}'), i treure la part de les referencies que parla del apartat del article referit
(a partir del caràcter '\texttt{|}').


\subsubsection{Llista de fitxers en un directori}
\begin{lstlisting}
  //donada una string de directori, retorna la llista de fitxers que conté
  def llistaFitxers(dir: String):List[String] = new File(dir).listFiles.filter(_.isFile).toList.map{a => dir + "/" + a.getName}
\end{lstlisting}

A partir del nom d'un directori, ens torna una llista amb els paths dels fitxers del directori.
Per fer-ho usem funcions del Java.

\subsection{Funció del Apartat 2 de la Pràctica}

Tenim tota la segona part de la pràctica en la següent funció, que rep una n corresponent als n-grames que volem utilitzar per fer les funcions, el systemActor per poder iniciar actors, i el nombre de workers que volem que el MapReduce utilitzi:

\begin{lstlisting}
  def calcularSimilituds(n: Int, system: ActorSystem, numWorkers: Int)= {
    type Fitxer = (String,(List[(String,Double)],List[String]))

    val fitxers = llistaFitxers(DirectoriFitxers)//input
    ...
  }
\end{lstlisting}

\subsubsection{Llegir Fitxers i tractar-los}

Aquesta primera part definim un alies pels fitxers, i aconseguim la llista de fitxers a tractar.

A continuació vindria un MapReduce per a la lectura de fitxers. Aquest treballarà així:
\begin{enumerate}
  \item El map s'encarregarà de llegir cada fitxer de disc, convertint-lo en un element de tipus (String, String, List[String]), sent aquests el títol del article, el contingut d'aquest, i la seva llista de referències a altres articles.
  \item El reduce calcularà la freqüència \textit{tf} de cada fitxer.
\end{enumerate}

\begin{lstlisting}
  //funció que llegeix i tracta un fitxer resultat en el títol, el contingut, i una llista de referències.
    def mapFunctionReadFiles(file:String):(String, (String, List[String])) = {
      val valors = tractaXMLdoc(file)
      (valors._1,(valors._2,valors._3))
    }

    //funció que a partir d'un fitxer en format(Títol, (Contingut, Referencies), calcula les frequencies TF en el contingut
    def reduceFunctionReadFiles(fileContent:(String, (String, List[String]))):Fitxer =
      (fileContent._1, (freqAtf(nonStopFreq(fileContent._2._1,stopWords,1)), fileContent._2._2))


    //Fem l'actor del MapReduce
    val act = system.actorOf(Props(
      new MapReduceFramework[String, String, (String,List[String]),String, (String,List[String]),String, (List[(String, Double)], List[String])](
        {f:String => List(mapFunctionReadFiles(f))},
        {f:List[(String, (String, List[String]))]=>f},
        {(f:String, s:(String, List[String])) => List(reduceFunctionReadFiles((f,s)))},
        numWorkers,numWorkers,fitxers)
    ))

    //L'hi enviem el missatge de inicialització al MapReduce, després esperem el resultat, usant un pattern.
    implicit val timeout = Timeout(12000,TimeUnit.SECONDS)
    val futur = act ? Iniciar()
    val diccionariFitxers = Await.result(futur,timeout.duration).asInstanceOf[mutable.Map[String, (List[(String, Double)], List[String])]]
    //parem l'actor
    act ! PoisonPill
\end{lstlisting}

\subsubsection{Càlcul del vector IDF}

Després la funció faria un mapReduce per calcular el vector \textit{idf}. Aquest funcionaria així:

\begin{itemize}
  \item el map ens genera tuples (paraules,valors) amb cada paraula diferent de cada fitxer, inicialitzat a 1.
  \item una funció intermèdia que ens agrupa les paraules iguals
  \item el reduce agafa cada grup d'aquests, i en calcula el valor \textit{idf}
\end{itemize}

\begin{lstlisting}
  //funció que rep un fitxer i resulta en una Llista de parelles de paraules diferents en el fitxer, i el número 1
  def mapFunctionIDF(fitxer:Fitxer):List[(String,Double)] =
    (fitxer._2)._1.map{x=>(x._1,1.0)}

  //funció que rep una parella amb una Paraules i Llista de Paraules(iguals) i nombres,
  // la funció conta la llargada de la funció
  def reduceFunctionIDF(dades:(String,List[(String,Double)])):(String,Double) =
    (dades._1, log10(nombreFitxers/ dades._2.foldLeft(0){ (a, _)=>a+1}))

  //funció que rep una Llista de paraules inicialitzades a 1,
  // la funció agrupa les paraules iguals en llistes de parelles Paraula, grup de (paraules, nombre)
  def funcioIntermitjaIDF(dades:List[(String,Double)]):List[(String,List[(String,Double)])] =
    dades.groupBy(_._1).toList


  //Fem l'actor del MapReduce
  val act2 = system.actorOf(Props (new MapReduceFramework[Fitxer,
    String,Double,String,List[(String,Double)],String,Double](
    {f=>mapFunctionIDF(f)},
    {f=>funcioIntermitjaIDF(f)},
    {(f:String,s:List[(String,Double)])=>List(reduceFunctionIDF((f,s)))},
    numWorkers,numWorkers,diccionariFitxers.toList
  )))

  //L'hi enviem el missatge de inicialització al MapReduce, després esperem el resultat, usant un pattern.
  val futur2 = act2 ? Iniciar()
  val diccionariIDF = Await.result(futur2,timeout.duration).asInstanceOf[mutable.Map[String, Double]]
  //parem l'actor
  act2 ! PoisonPill
\end{lstlisting}

\subsubsection{Comparacions tots amb tots}

En aquest punt tocaria fer la comparació dels fitxers tots amb tots. Això òbviament amb un MapReduce:
\begin{itemize}
  \item el map s'encarregarà de aplicar el \textit{idf} de cada paraula als vectors \textit{tf}.
  \item una funció intermèdia que s'encarregarà de generar cada possible comparació evitant simetries.
  \item el reduce farà les comparacions de cada fitxer amb els que li toquin.
\end{itemize}

\begin{lstlisting}
  //funció que multplica el IDF corresponent per a cada tf de cada paraula, formant el vector TF_IDF de un fitxer donat.
  def mapComparacio(fitxer:Fitxer):Fitxer =
    (fitxer._1, (fitxer._2._1.map{f=> (f._1,f._2 * diccionariIDF(f._1))}, fitxer._2._2))

  //funció que donada una llista de fitxers, per cada fitxer, genera una Llista amb tots els fitxers següents
  def generarComparacions(fitxers:List[Fitxer]):List[(Fitxer,List[Fitxer])] = {
    if (fitxers.isEmpty) Nil:List[(Fitxer,List[Fitxer])]
    else {
      val fitxersSenseCap = fitxers.tail
      List((fitxers.head, fitxersSenseCap)) ::: generarComparacions(fitxersSenseCap)
    }
  }

  //funció que donada una comparació d'un fitxer amb una llista de fitxers,
  // resulta en una tupla amb el títol del fitxer i una Llista de parelles amb títols de fitxers i resultats de comparacions
  def reduceComparacio(comparacions:(Fitxer,List[Fitxer])):(String, List[(String, Double)]) =
    (comparacions._1._1, for(f <- comparacions._2) yield (f._1, cosinesim(comparacions._1._2._1,f._2._1)))


  //Fem l'actor del MapReduce
  val act3 = system.actorOf(Props (new MapReduceFramework[Fitxer,
    String,(List[(String,Double)],List[String]),
    Fitxer, List[Fitxer],
    String, List[(String, Double)]](
    {f=>List(mapComparacio(f))},
    {f=>generarComparacions(f)},
    {(f:Fitxer,s:List[Fitxer])=>List(reduceComparacio((f,s)))},
    numWorkers,numWorkers,diccionariFitxers.toList
  )))
  //L'hi enviem el missatge de inicialització al MapReduce, després esperem el resultat, usant un pattern.
  val futur3 = act3 ? Iniciar()
  val resultatComparacions = Await.result(futur3,timeout.duration).asInstanceOf[mutable.Map[String, List[(String, Double)]]].toList.sortBy(-_._2.length)
  //parem l'actor
  act3 ! PoisonPill
\end{lstlisting}

Amb això el primer apartat de la segona part de la Pràctica estaria acabat, faltant el segon.

\subsubsection{Tractant referències}
El segon apartat consisteix en buscar els articles amb similituds per sobre d'un llindar però que no es referenciïn
i fitxers que es referenciïn però no estiguin per sobre de cert altre llindar. Les dos les hem fet amb mètodes semblants, Un MapReduce per cada un que no fa res en el Reduce.
\begin{itemize}
  \item el map s'encarrega de filtrar els elements per {sobre \texttt{||} sota} d'un llindar que {no es \texttt{||} sí es} referenciïn.
  \item no hi ha cap funció de tractament intermedi.
  \item no hi ha cap funció de reducció
\end{itemize}

Primer doncs, el primer cas, sent aquest el cas en què busquem parelles per sobre de cert llindar que no es referenciïn:
\begin{lstlisting}
  //donada llista referencies
    //map: eliminar els que no superin cert llindar, despres eliminar els no referenciats
    def mapObtenirNoRefs(fitxer:(String, List[(String, Double)])):(String, List[(String, Double)]) ={
      (fitxer._1,fitxer._2.filter(_._2>LlindarNoReferenciats).filter{
        f => !diccionariFitxers(fitxer._1)._2.contains(f._1) && !diccionariFitxers(f._1)._2.contains(fitxer._1)
      })
    }
    //Fem l'actor del MapReduce
    val act4 = system.actorOf(Props (new MapReduceFramework[
      (String, List[(String, Double)]),
      String,List[(String, Double)],
      String, List[(String, Double)],
      String, List[(String, Double)]]
    (
      {f=>List(mapObtenirNoRefs(f))},
      {f=>f},
      {(f:String, s:List[(String, Double)])=>scala.List((f,s))},
      numWorkers,numWorkers,resultatComparacions
    )))

    //L'hi enviem el missatge de inicialització al MapReduce, després esperem el resultat, usant un pattern.
    val futur4 = act4 ? Iniciar()
    val resultatObtenirNoRefs = Await.result(futur4,timeout.duration).asInstanceOf[mutable.Map[String, List[(String, Double)]]].toList.sortBy(-_._2.length)
    //parem l'actor
    act4 ! PoisonPill
\end{lstlisting}

I per acabar el cas en què busquem parelles per sota de cert llindar que es referenciïn:

\begin{lstlisting}
  //donada llista referencies
  //map: eliminar els que no arribin a cert llindar, despres eliminar els referenciats
  def mapObtenirRefsDiferents(fitxer:(String, List[(String, Double)])):(String, List[(String, Double)]) = (
    fitxer._1,fitxer._2.filter(_._2>LlindarReferenciats).filter{
    f => diccionariFitxers(fitxer._1)._2.contains(f._1) || diccionariFitxers(f._1)._2.contains(fitxer._1)
  })
  //Fem l'actor del MapReduce
  val act5 = system.actorOf(Props (new MapReduceFramework[
    (String, List[(String, Double)]),
    String,List[(String, Double)],
    String, List[(String, Double)],
    String, List[(String, Double)]]
  (
    {f=>List(mapObtenirRefsDiferents(f))},
    {f=>f},
    {(f:String, s:List[(String, Double)])=>scala.List((f,s))},
    numWorkers,numWorkers,resultatComparacions
  )))

  val futur5 = act5 ? Iniciar()
  val resultatObtenirRefsDiferents = Await.result(futur5,timeout.duration).asInstanceOf[mutable.Map[String, List[(String, Double)]]].toList.sortBy(-_._2.length)
  //parem l'actor
  act5 ! PoisonPill
\end{lstlisting}

\subsubsection{Volcatge dels resultats en un fitxer}

Usant les funcions de entrada-sortida del Java, fiquem el contingut resultant en fitxers per a cada variable:
\begin{lstlisting}
  val output = "output/"+DirectoriFitxers + "/"
  val nomDiccionari = output + "diccionari_"+n+".txt"
  val nomVectorIDF = output + "vectorIDF_"+n+".txt"
  val nomResultatComparacions = output + "resultatComparacions_"+n+".txt"
  val nomResultatRefs1 = output + "resultatRefs1_"+n+".txt"
  val nomResultatRefs2 = output + "resultatRefs2_"+n+".txt"

  val fitxerInicial = new File(nomDiccionari)
  fitxerInicial.getParentFile.mkdirs()
  var pw = new PrintWriter(fitxerInicial)
  diccionariFitxers.foreach{f=>
    pw.println("===" + f._1 + "\n====Llista Freqüències======")
    f._2._1.foreach{elem =>
      pw.println("    " + elem._1 + "-> " + elem._2.toString)
    }
    pw.println("====Llista Referències======")
    f._2._2.foreach{elem =>
      pw.println("    " + elem)
    }
    pw.print("\n\n")
  }
  pw.close()

  pw = new PrintWriter(new File(nomVectorIDF))
  diccionariIDF.foreach{f=>
    pw.println(f._1 + " -> " + f._2.toString)
  }
  pw.close()

  pw = new PrintWriter(new File(nomResultatComparacions))
  resultatComparacions.foreach{f=>
    if(f._2.nonEmpty) pw.println("===" + f._1 + "\n====Resultats Comparacions======")
    f._2.foreach{element=>
      pw.println("    " + element._1 + "-> " + element._2.toString)
    }
  }
  pw.close()

  pw = new PrintWriter(new File(nomResultatRefs1))
  resultatObtenirNoRefs.foreach{f=>
    if(f._2.nonEmpty) pw.println("===" + f._1 + "\n====Resultats Comparacions======")
    f._2.foreach{element=>
      pw.println("    " + element._1 + "-> " + element._2.toString)
    }
  }
  pw.close()

  pw = new PrintWriter(new File(nomResultatRefs2))
  resultatObtenirRefsDiferents.foreach{f=>
    if(f._2.nonEmpty) pw.println("===" + f._1 + "\n====Resultats Comparacions======")
    f._2.foreach{element=>
      pw.println("    " + element._1 + "-> " + element._2.toString)
    }
  }
  pw.close()
\end{lstlisting}

\subsection{Main de l'aplicació}

El main es divideix en dues parts:
\begin{itemize}
  \item Una referent a la primera part de la pràctica.
  \item Una altre referent a la segona part de la pràctica
\end{itemize}

\subsubsection{Primera part}

\begin{lstlisting}
  override def main(args: Array[String]): Unit = {
    val filename = "pg11.txt"
    val fileContents = Source.fromFile(filename).mkString

    val filename2 = "english-stop.txt"
    val englishStopWords = getStopWords(filename2)

    val llistaFreq = freq(fileContents,1).sortBy(-_._2)
    val nParules = llistaFreq.foldLeft(0){(a,b) => b._2+a}
    val diff = llistaFreq.size
    println(String.format("%-20s %-10s %-20s %-20s", "Num de Parules:", nParules.toString, "Diferents", diff.toString))
    println(String.format("%-20s %-20s %-20s ", "Paraules", "ocurrencies", "frequencia"))
    println("------------------------------------------------------")
    val sFormat = "%-20s %-20s %-1.3f "
    for (p <- llistaFreq.slice(0,10)) println(String.format(sFormat, p._1, p._2.toString, (p._2*100.0/nParules).toFloat:java.lang.Float))

    println("\n\nCàlcul primer fitxer sense stopWords\n")
    println("debug")
    val llistaNonStop = nonStopFreq(fileContents, englishStopWords, 1).sortBy(-_._2)
    println(String.format("%-20s %-20s %-20s ", "Paraules", "ocurrencies", "frequencia"))
    println("------------------------------------------------------")
    for (p <- llistaNonStop.slice(0,10)) println(String.format(sFormat, p._1, p._2.toString, (p._2*100.0/nParules).toFloat:java.lang.Float))

    println("\n\nn-grames del primer fitxer amb n = 3\n")
    val llistaNgrames = freq(fileContents, 3).sortBy(-_._2)

    for (p <- llistaNgrames slice (0, 10)) println(String.format("%-30s %-5s", p._1, p._2.toString))

    println("Distribució de paraules")
    paraulafreqfreq(llistaFreq)

    val filename3 = "pg74.txt"
    println("\n\nComparació de pg11.txt amb pg74.txt utilitzant el cosinesim\n")

    val start = System.nanoTime()
    val newFileContents = Source.fromFile(filename).mkString
    val fileContents2 = Source.fromFile(filename3).mkString

    val freq1 = nonStopFreq(newFileContents, englishStopWords,1).sortBy(-_._2)
    val freq2 = nonStopFreq(fileContents2, englishStopWords, 1).sortBy(-_._2)

    val txt1 = freqAtf(freq1)
    val txt2 = freqAtf(freq2)

    val resCosinesim = cosinesim(txt1, txt2)

    val end = System.nanoTime()
    println(resCosinesim)
    println("El cosinesim ha tardat: " + (end-start).toDouble/1000000000.0)
...
  }
\end{lstlisting}

\subsubsection{Segona Part}

\begin{lstlisting}
  println("\n\n\n\nINICI DEL CAMP MINAT: \n")

  val system = ActorSystem("SystemActor")

  val maxNgrames = 1

  for(n <- 1 to maxNgrames){
    calcularSimilituds(n,system)
  }

  system.terminate()
\end{lstlisting}

La funció de la segona part s'executa de 1 fins a maxNgrames, podent determinar quin es el màxim on volem arribar.


\section{Fitxer MapReduceFramework.scala}

Aquest fitxer inclou la classe amb el MapReduceFramework, que és la nostre implementació genèrica del mapReduce.

\subsection{Idea General}
La idea és un map reduce que rep unes dades, funció de mapping, funció de reducing, funció intermèdia, els nombres d'actors de mappeig i de reducció.
Al rebre la crida Iniciar(), inicia el procediment. Usa la funció de mappeig sobre les dades, aplica la funció intermèdia amb els resultats, i sobre això aplica la funció de reducció.

\subsection{Signatura}

\begin{lstlisting}
  class MapReduceFramework[Input, ClauMap, ValorMap, ClauIntermitja, ValorIntermig, ClauSortida, ValorSortida]
(
  mapFunction:Input=>List[(ClauMap, ValorMap)],
  funcioIntermitja:List[(ClauMap, ValorMap)] => List[(ClauIntermitja, ValorIntermig)] ,
  reduceFunction:(ClauIntermitja, ValorIntermig)=>List[(ClauSortida, ValorSortida)],
  nombreActorsMap: Int,
  nombreActorsReduce: Int,
  input: List[Input]
) extends Actor{
\end{lstlisting}

\subsubsection{Sobre el Tipatge}

\begin{itemize}
  \item Input, el tipus de cada element de la Llista de dades entrada.
  \item ClauMap, el tipus de les claus resultants després del mappeig.
  \item ValorMap, el tipus dels valors resultants després del mappeig.
  \item ClauIntermitja, el tipus de les claus resultants després del tractament de dades intermedi.
  \item ValorIntermig, el tipus dels valors resultants després del tractament de dades intermedi.
  \item ClauSortida, el tipus de les claus resultants després de la funció de reducció.
  \item ValorSortida, el tipus dels valors resultants després de la funció de reducció.
\end{itemize}

\subsection{Classes internes}

\begin{lstlisting}
  case class MissatgeMapeig(dades:Input)
  case class RespostaMapeig(dades:List[(ClauMap,ValorMap)])
  case class MissatgeReduccio(dades:(ClauIntermitja, ValorIntermig))
  case class RespostaReduccio(dades:List[(ClauSortida,ValorSortida)])
\end{lstlisting}

Les primeres case classes son per fer el \textit{pattern matching} referent a la recepció de missatges.

\subsection{Inicialització de valors}
\begin{lstlisting}
  val inici: Long = System.nanoTime()
  var pendent = 0
  var pare:ActorRef = _
  var llistaIntermedia:List[(ClauMap, ValorMap)] = Nil
  var resultat:mutable.Map[ClauSortida,ValorSortida] = mutable.Map[ClauSortida,ValorSortida]()
\end{lstlisting}

S'inicialitza el temps de inici i els elements pendents de tractar. Creem variables pare (referent al creador del actor).
LlistaIntermedia i resultat són la llista i el map (respectivament) a construir amb les dades que tornen el map i el reduce (respectivament).

\subsection{Definició dels routers de Map i Reduce}

\begin{lstlisting}
  val MapRouter: ActorRef = context.actorOf(RoundRobinPool(nombreActorsMap).props(Props(new Actor{
    override def receive: Receive = {
      case MissatgeMapeig(dades) => sender ! RespostaMapeig(mapFunction(dades))
    }})))
  val ReduceRouter: ActorRef = context.actorOf(RoundRobinPool(nombreActorsReduce).props(Props( new Actor{
    override def receive: Receive = {
      case MissatgeReduccio(fitxer) => sender ! RespostaReduccio(reduceFunction(fitxer._1,fitxer._2))
    }
  })))
\end{lstlisting}

Per a la generació d'actors, hem utilitzat RoundRobin per crear un enroutador d'actors que s'encarregui del balanceig de càrregues i supervisió de fallades.

Els inicialitzem amb classes anònimes, que cada una rep un missatge ordenant mappeig o reducció i respon amb el resultat de aplicar a les dades la funció de de mappeig o reducció, segons el que toqui.

\subsection{Funció de receive}

\begin{lstlisting}
  override def receive: Receive = {
    case Iniciar() =>
      pare = sender
      println("Iniciem el MapReduceFramework")
      input.foreach{
        f=>MapRouter ! MissatgeMapeig(f)
          pendent+=1}
    case RespostaMapeig(dades) =>
      pendent-=1
      llistaIntermedia = dades ::: llistaIntermedia
      if (pendent == 0){
        context.stop(MapRouter)
        println("--------Duració mapeig: " + (System.nanoTime()-inici).toDouble/1000000000.0 + " segons")
        funcioIntermitja(llistaIntermedia).foreach {
          f => ReduceRouter ! MissatgeReduccio(f)
            pendent+=1
        }
        println("--------Duració Fins Intermig: " + (System.nanoTime()-inici).toDouble/1000000000.0 + " segons")
      }
    case RespostaReduccio(dades) =>
      pendent -=1
      dades.foreach{a => resultat+=(a._1->a._2)}
      if (pendent == 0){
        context.stop(ReduceRouter)
        val fi = System.nanoTime()
        println("Duració: " + (fi-inici).toDouble/1000000000.0 + " segons")
        pare ! resultat
      }
  }
\end{lstlisting}

La funció es divideix en tres casos, en funció del missatge rebut:
\begin{enumerate}
  \item Iniciar(): Aquest missatge és l'ordre de inici d'execució del mapReduce. Hem de guardar el valor del para, i enviem cada dada de la input al MapRouter, actualitzant el pendent
  \item RespostaMapeig(): Missatge amb resposta d'un MapWorker, hem de actualitzar la llista de pendents, i afegir el rebut a la llista de valors intermedis, quan ja no en queden més, acabar el MapRouter, passar la funció intermèdia, i enviar cada dada d'aquesta al ReduceRouter.
  \item RespostaReduccio(): Missatge amb resposta d'un ReduceWorker, hem de actualitzar la llista de pendents i actualitzar el resultat final. Quan no queden més, acabem el RouterWorker i responem al pare.
\end{enumerate}




\chapter{Joc de proves}

\section{Resultats amb els fitxers donats}

\subsection{pg11.txt}
\small{\verbatiminput{result-pg11.txt}}

\subsection{pg11-net.txt}
\small{\verbatiminput{result-pg11-net.txt}}

\subsection{pg12.txt}
\small{\verbatiminput{result-pg12.txt}}

\subsection{pg12-net.txt}
\small{\verbatiminput{result-pg12-net.txt}}

\subsection{pg74.txt}
\small{\verbatiminput{result-pg74.txt}}

\subsection{pg74-net.txt}
\small{\verbatiminput{result-pg74-net.txt}}

\subsection{pg2500.txt}
\small{\verbatiminput{result-pg2500.txt}}

\subsection{pg2500-net.txt}
\small{\verbatiminput{result-pg2500-net.txt}}

\section{Resultat amb Fitxer personalitzat}
\subsection{Contingut del fitxer}
\small{\verbatiminput{FitxerProva.txt}}

\subsection{Resultat}
\small{\verbatiminput{result-FitxerProva.txt}}

\section{Resultats Cosinesim}
Les proves d'aquesta secció han estat fetes amb la següent màquina:

Les següents proves s'han fet amb la següent màquina:
\begin{itemize}
  \item CPU: AMD Ryzen 3 1200 amb 4 cores i 4 threads a una freqüència base de 3.10GHz i una freqüència turbo 3.4GHz
  \item RAM: 8GB
  \item Almacenatge: HDD
\end{itemize}

\subsection{pg-11.txt amb pg11-net.txt}
Resultat: 0.9532862678863194

El cosinesim ha tardat: 0.376971377 segons

\subsection{pg-11.txt amb pg74.txt}
Resultat: 0.29079706998634325

El cosinesim ha tardat: 0.460658575 segons

\subsection{pg-12.txt amb pg74.txt}
Resultat: 0.2898070543611612

El cosinesim ha tardat: 0.463819116 segons

\subsection{pg-12.txt amb pg-12.txt}
Resultat: 0.9999999999997916

El cosinesim ha tardat: 0.416221798 segons





\chapter{Resultats}

El temps d'execució al calcular l'exercici amb la maquina esmentada aqui baix és d'aproximadament 55 minuts. Per això, hem creat dos subsets de test per poder provar canvis al codi fàcilment, un que conté tots els arxius acabats en "91.xml",
 i un altre amb tots els arxius acabats en "9.xml". Els resultats de la nostra execució general estan penjats a \url{https://drive.google.com/file/d/1LoqFrBAbluANe4F8Xv41rmG6mQjydSAV/view?usp=sharing}

\section{Taula de rendiment de MapReduce segons nombre d'actors}

Les següents proves s'han fet amb la següent màquina:
\begin{itemize}
  \item CPU: Intel Core i5 6600 amb 4 cores i 4 threads a una freqüència base de 3.30GHz i una freqüència turbo de 3.90GHz
  \item RAM: 16GB
  \item Emmagatzematge: Samsung 960 EVO NVMe
\end{itemize}


\begin{tabular}{|c|c|}
  \hline
  \rowcolor[HTML]{ECF4FF}
  \textbf{Nombre d'actors} & \textbf{Temps transcorregut} \\ \hline
  1                        & 150.21s                      \\ \hline
  2                        & 76.03s                       \\ \hline
  4                        & 47.00s                       \\ \hline
  8                        & 44.33s                       \\ \hline
  16                       & 45.48s                       \\ \hline
  32                       & 48.55s                       \\ \hline
  64                       & 44.35s                       \\ \hline
  128                      & 46.25                        \\ \hline
\end{tabular}

\section{Taula d'articles a referenciar segons llindar}

Hem decidit usar un llindar de 0.01 basant-nos en els resultats obtinguts en tests més petits. La taula obtinguda en aquests tests és la següent:

\begin{tabular}{|c|c|}
\hline
\rowcolor[HTML]{ECF4FF}
\textbf{Llindar}            & \textbf{Nombre d'articles a referenciar} \\ \hline
\multicolumn{1}{|c|}{0.001} & \multicolumn{1}{c|}{97100}               \\ \hline
\multicolumn{1}{|c|}{0.005} & \multicolumn{1}{c|}{59440}               \\ \hline
\multicolumn{1}{|c|}{0.01}  & \multicolumn{1}{c|}{30119}               \\ \hline
\multicolumn{1}{|c|}{0.05}  & \multicolumn{1}{c|}{2209}                \\ \hline
\multicolumn{1}{|c|}{0.1}   & \multicolumn{1}{c|}{567}                 \\ \hline
\multicolumn{1}{|c|}{0.5}   & \multicolumn{1}{c|}{7}                   \\ \hline
\end{tabular}

\section{Ex.3 de la segona part de la pràctica}

Sembla que canviar la longitud dels n-grames de 1 a 5 no afecta al nombre de pagines similars que no es referencien. Suposem que això és degut a que el idf canviaria proporcionalment al tf, i els canvis als dos, al fer les comparacions, es cancelarien i ens quedaria el mateix resultat.

\end{document}

